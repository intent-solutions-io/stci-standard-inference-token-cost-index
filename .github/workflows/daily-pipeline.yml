name: Daily Pipeline

on:
  schedule:
    # Run daily at 00:30 UTC
    - cron: '30 0 * * *'
  workflow_dispatch:
    inputs:
      date:
        description: 'Date to collect (YYYY-MM-DD, default: today)'
        required: false
        type: string

env:
  PROJECT_ID: stci-production

permissions:
  contents: write
  id-token: write  # Required for WIF

jobs:
  collect-and-index:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: projects/303527277450/locations/global/workloadIdentityPools/github-pool/providers/github-provider
          service_account: github-actions@stci-production.iam.gserviceaccount.com

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Cache pip packages
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Determine date
        id: date
        run: |
          if [ -n "${{ inputs.date }}" ]; then
            echo "date=${{ inputs.date }}" >> $GITHUB_OUTPUT
          else
            echo "date=$(date -u +%Y-%m-%d)" >> $GITHUB_OUTPUT
          fi

      - name: Run multi-source collector
        env:
          OPENROUTER_API_KEY: ${{ secrets.OPENROUTER_API_KEY }}
        run: |
          python -m services.collector.pipeline --multi --date ${{ steps.date.outputs.date }}

      - name: Run indexer
        run: |
          python -m services.indexer.pipeline --date ${{ steps.date.outputs.date }}

      - name: Verify outputs
        run: |
          echo "=== Index ==="
          cat data/indices/${{ steps.date.outputs.date }}.json | python -c "
          import sys, json
          d = json.load(sys.stdin)
          print(f\"Date: {d['date']}\")
          print(f\"Observations: {d['observation_count']}\")
          print(f\"Hash: {d['verification_hash']}\")
          for name, data in d['indices'].items():
              print(f\"  {name}: \${data['blended_rate']:.2f}/1M ({data['model_count']} models)\")
          "

      - name: Upload to Firestore
        run: |
          python << 'EOF'
          from google.cloud import firestore
          import json

          db = firestore.Client(project='stci-production')

          # Upload index
          with open('data/indices/${{ steps.date.outputs.date }}.json') as f:
              index_data = json.load(f)
              db.collection('indices').document('${{ steps.date.outputs.date }}').set(index_data)
          print('Uploaded index to Firestore')

          # Upload observations
          observations = []
          with open('data/observations/${{ steps.date.outputs.date }}.jsonl') as f:
              for line in f:
                  observations.append(json.loads(line))

          db.collection('observations').document('${{ steps.date.outputs.date }}').set({
              'date': '${{ steps.date.outputs.date }}',
              'count': len(observations),
              'items': observations
          })
          print(f'Uploaded {len(observations)} observations to Firestore')

          # Update methodology
          methodology = {
              'version': '1.0.0',
              'description': 'Standard Token Cost Index methodology',
              'indices': ['STCI-ALL', 'STCI-FRONTIER', 'STCI-EFFICIENT', 'STCI-OPEN'],
              'sources': ['openrouter', 'openai_direct', 'anthropic_direct', 'google_direct'],
              'updated': '${{ steps.date.outputs.date }}'
          }
          db.collection('methodology').document('current').set(methodology)
          print('Updated methodology')
          EOF

      - name: Commit data
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add data/
          git diff --staged --quiet || git commit -m "Daily update: ${{ steps.date.outputs.date }}"
          git push
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: stci-${{ steps.date.outputs.date }}
          path: |
            data/indices/${{ steps.date.outputs.date }}.json
            data/observations/${{ steps.date.outputs.date }}.jsonl
          retention-days: 30

      - name: Pipeline summary
        run: |
          echo "## Daily Pipeline Complete" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Date:** ${{ steps.date.outputs.date }}" >> $GITHUB_STEP_SUMMARY
          echo "**API:** https://inferencepriceindex.com/v1/index/${{ steps.date.outputs.date }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          cat data/indices/${{ steps.date.outputs.date }}.json | python -c "
          import sys, json
          d = json.load(sys.stdin)
          print('| Index | Rate | Models |')
          print('|-------|------|--------|')
          for name, data in d['indices'].items():
              print(f\"| {name} | \${data['blended_rate']:.2f}/1M | {data['model_count']} |\")
          " >> $GITHUB_STEP_SUMMARY
